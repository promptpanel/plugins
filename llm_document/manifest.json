{
  "name": "LLM  - Docs",
  "category": "Document (RAG)",
  "settings": [
    {
      "name": "Model",
      "description": "The language model you want to use. Any LiteLLM model provider is available: https://docs.litellm.ai/docs/providers",
      "default": "gpt-4-0125-preview",
      "type": "text",
      "selections": [
        {
          "group": "OpenAI",
          "values": [
            "gpt-4-0125-preview",
            "gpt-3.5-turbo-0125",
            "gpt-3.5-turbo",
            "gpt-4"
          ]
        },
        {
          "group": "Google Gemini",
          "values": [
            "gemini/gemini-pro"
          ]
        },
        {
          "group": "Anthropic",
          "values": [
            "claude-3-haiku-20240307",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-2.1",
            "claude-2",
            "claude-instant-1.2",
            "claude-instant-1"
          ]
        },
        {
          "group": "Cohere",
          "values": [
            "command-r",
            "command-light",
            "command-medium",
            "command-medium-beta",
            "command-xlarge-nightly",
            "command-nightly"
          ]
        },
        {
          "group": "Mistral AI API",
          "values": [
            "mistral/mistral-tiny",
            "mistral/mistral-small",
            "mistral/mistral-medium",
            "mistral/mistral-large-latest"
          ]
        }
      ],
      "required": true
    },
    {
      "name": "Simple Model",
      "description": "Used for miscellaneous tasks like titling threads for lower cost.",
      "default": "gpt-3.5-turbo-0125",
      "type": "text",
      "selections": [
        {
          "group": "OpenAI",
          "values": [
            "gpt-4-0125-preview",
            "gpt-3.5-turbo-0125",
            "gpt-3.5-turbo",
            "gpt-4"
          ]
        },
        {
          "group": "Google Gemini",
          "values": [
            "gemini/gemini-pro"
          ]
        },
        {
          "group": "Anthropic",
          "values": [
            "claude-3-haiku-20240307",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-2.1",
            "claude-2",
            "claude-instant-1.2",
            "claude-instant-1"
          ]
        },
        {
          "group": "Cohere",
          "values": [
            "command-r",
            "command-light",
            "command-medium",
            "command-medium-beta",
            "command-xlarge-nightly",
            "command-nightly"
          ]
        },
        {
          "group": "Mistral AI API",
          "values": [
            "mistral/mistral-tiny",
            "mistral/mistral-small",
            "mistral/mistral-medium",
            "mistral/mistral-large-latest"
          ]
        }
      ],
      "required": true
    },
    {
      "name": "Embedding Model",
      "description": "The GPT-family embedding model you want to use.",
      "default": "text-embedding-ada-002",
      "type": "text",
      "selections": [
        {
          "group": "OpenAI",
          "values": [
            "text-embedding-ada-002",
            "text-embedding-3-large",
            "text-embedding-3-small"
          ]
        },
        {
          "group": "Cohere",
          "values": [
            "embed-english-v3.0",
            "embed-english-light-v3.0",
            "embed-multilingual-v3.0",
            "embed-multilingual-light-v3.0",
            "embed-english-v2.0",
            "embed-english-light-v2.0",
            "embed-multilingual-v2.0"
          ]
        }
      ]
    },
    {
      "name": "Sentence Transformer Embedding (Local)",
      "description": "Will take precedence over the Embedding Model defined above. Use HuggingFace repo to download, will then be usable offline.",
      "default": "",
      "type": "text",
      "selections": [
        "sentence-transformers/all-MiniLM-L6-v2",
        "sentence-transformers/all-mpnet-base-v2",
        "sentence-transformers/stsb-distilroberta-base-v2",
        "sentence-transformers/all-MiniLM-L12-v2"
      ]
    },
    {
      "name": "Context Size",
      "description": "The max context size your model supports.",
      "default": "4096",
      "type": "number",
      "required": true
    },
    {
      "name": "System Message",
      "description": "A message to help instruct the model on it's usage and how to behave.",
      "type": "textarea",
      "default": "You are a helpful AI assistant.",
      "required": true
    },
    {
      "name": "API Key",
      "description": "API access key for connecting to API.",
      "type": "text",
      "required": true
    },
    {
      "name": "Document Context",
      "description": "Number of tokens to use for document context.",
      "type": "number",
      "default": "1200",
      "advanced": true
    },
    {
      "name": "Max Tokens to Generate",
      "type": "number",
      "advanced": true
    },
    {
      "name": "URL Base",
      "type": "text",
      "advanced": true
    },
    {
      "name": "Organization ID",
      "description": "Used by some vendors to identify the organization using the API.",
      "type": "text",
      "advanced": true
    },
    {
      "name": "API Version",
      "description": "Used by some vendors to identify the API to use.",
      "type": "text",
      "advanced": true
    },
    {
      "name": "Temperature",
      "description": "Temperature as a setting that controls the AI's willingness to take risks in its word choices. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. (Between 0.0 to 2.0)",
      "type": "number",
      "advanced": true
    },
    {
      "name": "Top P",
      "description": "Top P controls the diversity of the AI's responses by only considering a subset of all possible next words that have a cumulative probability above a certain threshold. Recommended to use Temperature OR Top-P, not both. (Between 0.0 to 2.0)",
      "type": "number",
      "advanced": true
    },
    {
      "name": "Stop Sequence",
      "description": "Sequence where if generated the API will stop generating further tokens.",
      "type": "text",
      "advanced": true
    },
    {
      "name": "Presence Penalty",
      "description": "Aims to reduce the likelihood of the model repeating the same information or topics it has already mentioned in the current text generation task. (Between -2.0 to 2.0)",
      "type": "number",
      "advanced": true
    },
    {
      "name": "Frequency Penalty",
      "description": "Aims to decrease the repetition of individual words or phrases within the generated text. (Between -2.0 to 2.0)",
      "type": "number",
      "advanced": true
    }
  ]
}
